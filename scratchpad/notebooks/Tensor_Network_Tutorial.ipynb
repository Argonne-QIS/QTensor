{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Section-1:-Basic-usage.\" data-toc-modified-id=\"Section-1:-Basic-usage.-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Section 1: Basic usage.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Edge-centric-connection.\" data-toc-modified-id=\"Edge-centric-connection.-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Edge-centric connection.</a></span></li><li><span><a href=\"#Axis-naming.\" data-toc-modified-id=\"Axis-naming.-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Axis naming.</a></span></li></ul></li><li><span><a href=\"#Section-2.-Advanced-Network-Contractions\" data-toc-modified-id=\"Section-2.-Advanced-Network-Contractions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Section 2. Advanced Network Contractions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Avoid-trace-edges.\" data-toc-modified-id=\"Avoid-trace-edges.-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Avoid trace edges.</a></span></li><li><span><a href=\"#Complex-Contraction.\" data-toc-modified-id=\"Complex-Contraction.-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Complex Contraction.</a></span></li></ul></li><li><span><a href=\"#Section-3:-Node-splitting.\" data-toc-modified-id=\"Section-3:-Node-splitting.-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Section 3: Node splitting.</a></span></li><li><span><a href=\"#Section-4:-running-on-GPUs\" data-toc-modified-id=\"Section-4:-running-on-GPUs-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Section 4: running on GPUs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:16:32.446250Z",
     "start_time": "2020-06-10T19:16:31.342750Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "F41jzPsm_9tZ",
    "outputId": "5d4b81cd-7cea-40b9-a7b5-e4655179b3c7"
   },
   "outputs": [],
   "source": [
    "# !pip install tensornetwork jax jaxlib\n",
    "import numpy as np\n",
    "import jax\n",
    "import tensornetwork as tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaWIxu_4aBNj"
   },
   "source": [
    "# Section 1: Basic usage.\n",
    "In this section, we will go over basic linear algebra operations and how to create them using a TensorNetwork. While at first it may seem more complicated to use a tensornetwork rather than just doing the operations by hand, we will use the skills developed in this section to start building and contracting very complicated tensor networks that would be very difficult to do otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4i5M1zLbbsL"
   },
   "source": [
    "Let's begin by doing the most basic operation possible, a vector dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:21:53.490401Z",
     "start_time": "2020-06-10T19:21:53.463397Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R_9ZTrSoAah3",
    "outputId": "fcc9c983-29b0-4a95-ce85-7f3e34e7645d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "# Next, we add the nodes containing our vectors.\n",
    "a = tn.Node(np.ones(10))\n",
    "# Either tensorflow tensors or numpy arrays are fine.\n",
    "b = tn.Node(np.ones(10))\n",
    "# We \"connect\" these two nodes by their \"0th\" edges.\n",
    "# This line is equal to doing `tn.connect(a[0], b[0])\n",
    "# but doing it this way is much shorter.\n",
    "edge = a[0] ^ b[0]\n",
    "# Finally, we contract the edge, giving us our new node with a tensor\n",
    "# equal to the inner product of the two earlier vectors\n",
    "c = tn.contract(edge)\n",
    "# You can access the underlying tensor of the node via `node.tensor`.\n",
    "# To convert a Eager mode tensorflow tensor into \n",
    "print(c.tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gf_tCdk7lNeN"
   },
   "source": [
    "## Edge-centric connection.\n",
    "When a node is created in the TensorNetwork, that node is automatically filled with dangling-edges. To connect two nodes together, we actually remove the two danging edges in the nodes and replace them with a standard/trace edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:23:50.602909Z",
     "start_time": "2020-06-10T19:23:50.596957Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cLuYsq_clLTA",
    "outputId": "5a59d282-5b50-4991-c84e-f3b0524c2e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of a[0] is: <class 'tensornetwork.network_components.Edge'>\n",
      "Is a[0] dangling?: True\n"
     ]
    }
   ],
   "source": [
    "a = tn.Node(np.eye(2))\n",
    "# Notice that a[0] is actually an \"Edge\" type.\n",
    "print(\"The type of a[0] is:\", type(a[0]))\n",
    "# This is a dangling edge, so this method will \n",
    "print(\"Is a[0] dangling?:\", a[0].is_dangling())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySDV2F3lm5_S"
   },
   "source": [
    "Now, let's connect a[0] to a[1]. This will create a \"trace\" edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:24:05.705290Z",
     "start_time": "2020-06-10T19:24:05.697091Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "L1BBz3Zymuea",
    "outputId": "ab473c27-a492-4a9a-9b6b-038c3d0faca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are a[0] and a[1] the same edge?: True\n",
      "Is a[0] dangling?: False\n"
     ]
    }
   ],
   "source": [
    "trace_edge = a[0] ^ a[1]\n",
    "# Notice now that a[0] and a[1] are actually the same edge.\n",
    "print(\"Are a[0] and a[1] the same edge?:\", a[0] is a[1])\n",
    "print(\"Is a[0] dangling?:\", a[0].is_dangling())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cW-IWA_l0By"
   },
   "source": [
    "## Axis naming.\n",
    "Sometimes, using the axis number is very inconvient and it can be hard to keep track of the purpose of certain edges. To make it easier, you can optionally add a name to each of the axes of your node. Then you can get the respective edge by indexing using the name instead of the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:24:20.637370Z",
     "start_time": "2020-06-10T19:24:20.628960Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M0k91fG9A-nc",
    "outputId": "61aebd0c-f0b9-4f2c-91b1-8da39c1c9fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "# Here, a[0] is a['alpha'] and a[1] is a['beta']\n",
    "a = tn.Node(np.eye(2), axis_names=['alpha', 'beta'])\n",
    "edge = a['alpha'] ^ a['beta']\n",
    "result = tn.contract(edge)\n",
    "print(result.tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srvhkdXyq93b"
   },
   "source": [
    "# Section 2. Advanced Network Contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgEhqwUV0tmd"
   },
   "source": [
    "## Avoid trace edges.\n",
    "While the TensorNetwork library fully supports trace edges, contraction time is ALWAYS faster if you avoid creating them. This is because trace edges only sum the diagonal of the underlying matrix, and the rest of the values (which is a majorit of the total values) are just garbage. You both waste compute time and memory by having these useless trace edges.\n",
    "\n",
    "The main way we support avoid trace edges is via the `@` symbol, which is an alias to `tn.contract_between`. Take a look at the speedups!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:24:32.869804Z",
     "start_time": "2020-06-10T19:24:24.224862Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "nqlIH0wOqvd0",
    "outputId": "bebafd5a-b435-4a0d-ae8e-4201149b260f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running one_edge_at_a_time\n",
      "41.6 ms ± 5.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Running use_cotract_between\n",
      "5.78 ms ± 1.13 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def one_edge_at_a_time(a, b):\n",
    "  node1 = tn.Node(a)\n",
    "  node2 = tn.Node(b)\n",
    "  edge1 = node1[0] ^ node2[0]\n",
    "  edge2 = node1[1] ^ node2[1]\n",
    "  tn.contract(edge1)\n",
    "  result = tn.contract(edge2)\n",
    "  return result.tensor\n",
    "\n",
    "def use_contract_between(a, b):\n",
    "  node1 = tn.Node(a)\n",
    "  node2 = tn.Node(b)\n",
    "  node1[0] ^ node2[0]\n",
    "  node1[1] ^ node2[1]\n",
    "  # This is the same as \n",
    "  # tn.contract_between(node1, node2)\n",
    "  result = node1 @ node2\n",
    "  return result.tensor\n",
    "\n",
    "a = np.ones((1000, 1000))\n",
    "b = np.ones((1000, 1000))\n",
    "print(\"Running one_edge_at_a_time\")\n",
    "%timeit one_edge_at_a_time(a, b)\n",
    "print(\"Running use_cotract_between\")\n",
    "%timeit use_contract_between(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFgUTwnt3Umg"
   },
   "source": [
    "We also have `contract_parallel` which does the same thing as `contract_between`, only you pass a single edge instead of two nodes. This will contract all of the edges \"parallel\" to the given edge (meaning all of the edges that share the same two nodes as the given edge).\n",
    "\n",
    "Using either method is fine and they will do the exact same thing. In fact, if you look at the source code, `contract_parallel` actually just calls `contract_between`. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:26:10.042483Z",
     "start_time": "2020-06-10T19:26:05.270948Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "aYXoLPNA22fm",
    "outputId": "c0786726-53a9-41f2-dc40-617c73cf166b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running contract_parallel\n",
      "5.76 ms ± 232 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def use_contract_parallel(a, b):\n",
    "  node1 = tn.Node(a)\n",
    "  node2 = tn.Node(b)\n",
    "  edge = node1[0] ^ node2[0]\n",
    "  node1[1] ^ node2[1]\n",
    "  result = tn.contract_parallel(edge)\n",
    "  # You can use `get_final_node` to make sure your network \n",
    "  # is fully contracted.\n",
    "  return result.tensor\n",
    "\n",
    "print(\"Running contract_parallel\")\n",
    "%timeit use_contract_parallel(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyUb_CyaZqmv"
   },
   "source": [
    "## Complex Contraction.\n",
    "Remember this crazy hard to write tensor contraction?\n",
    "Well, we're gonna do it in about 13 lines of simple code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:26:39.402840Z",
     "start_time": "2020-06-10T19:26:39.391310Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OzAlIQ9eyv8Z",
    "outputId": "ce5a2023-71ae-47cf-f842-29669fdbacbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.0\n"
     ]
    }
   ],
   "source": [
    "# Here, we will contract the following shaped network.\n",
    "# O - O\n",
    "# | X |\n",
    "# O - O\n",
    "a = tn.Node(np.ones((2, 2, 2)))\n",
    "b = tn.Node(np.ones((2, 2, 2)))\n",
    "c = tn.Node(np.ones((2, 2, 2)))\n",
    "d = tn.Node(np.ones((2, 2, 2)))\n",
    "# Make the network fully connected.\n",
    "a[0] ^ b[0]\n",
    "a[1] ^ c[1]\n",
    "a[2] ^ d[2]\n",
    "b[1] ^ d[1]\n",
    "b[2] ^ c[2]\n",
    "c[0] ^ d[0]\n",
    "# We are using the \"greedy\" contraction algorithm.\n",
    "# Other algorithms we support include \"optimal\" and \"branch\".\n",
    "\n",
    "# Finding the optimial contraction order in the general case is NP-Hard,\n",
    "# so there is no single algorithm that will work for every tensor network.\n",
    "# However, there are certain kinds of networks that have nice properties that\n",
    "# we can expliot to making finding a good contraction order easier.\n",
    "# These types of contraction algorithms are in developement, and we welcome \n",
    "# PRs!\n",
    "\n",
    "# `tn.reachable` will do a BFS to get all of the nodes reachable from a given\n",
    "# node or set of nodes.\n",
    "# nodes = {a, b, c, d}\n",
    "nodes = tn.reachable(a)\n",
    "result = tn.contractors.greedy(nodes)\n",
    "print(result.tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:26:52.015352Z",
     "start_time": "2020-06-10T19:26:51.998596Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "6xZybTdRVaeq",
    "outputId": "3babe82d-3251-4285-aebe-7b76c14b119f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(64.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make connecting a network a little less verbose, we have included\n",
    "# the NCon API aswell.\n",
    "\n",
    "# This example is the same as above.\n",
    "ones = np.ones((2, 2, 2))\n",
    "tn.ncon([ones, ones, ones, ones], \n",
    "        [[1, 2, 4], \n",
    "         [1, 3, 5], \n",
    "         [2, 3, 6],\n",
    "         [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:27:08.206447Z",
     "start_time": "2020-06-10T19:27:08.189801Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2x1GbZcYWTrT",
    "outputId": "dbffe7a7-214f-45c5-e8d7-789b2dca5676"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2.],\n",
       "       [2., 2.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To specify dangling edges, simply use a negative number on that index.\n",
    "\n",
    "ones = np.ones((2, 2))\n",
    "tn.ncon([ones, ones], [[-1, 1], [1, -2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SQz6EzVuOnk"
   },
   "source": [
    "# Section 3: Node splitting.\n",
    "In the final part of this colab, will go over the SVD node splitting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:27:13.702534Z",
     "start_time": "2020-06-10T19:27:13.698633Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hVOluV8-4YPD"
   },
   "outputs": [],
   "source": [
    "# To make the singular values very apparent, we will just take the SVD of a\n",
    "# diagonal matrix.\n",
    "diagonal_array = np.array([[2.0, 0.0, 0.0],\n",
    "                           [0.0, 2.5, 0.0],\n",
    "                           [0.0, 0.0, 1.5]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:27:15.268607Z",
     "start_time": "2020-06-10T19:27:15.248840Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "DUc-1xWnwcDY",
    "outputId": "da57a616-4594-417c-94ce-ed01f5aa7668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U node\n",
      "[[0.         1.41421356 0.        ]\n",
      " [1.58113883 0.         0.        ]\n",
      " [0.         0.         1.22474487]]\n",
      "\n",
      "V* node\n",
      "[[0.         1.58113883 0.        ]\n",
      " [1.41421356 0.         0.        ]\n",
      " [0.         0.         1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "# First, we will go over the simple split_node method.\n",
    "a = tn.Node(diagonal_array)\n",
    "u, vh, _ = tn.split_node(\n",
    "    a, left_edges=[a[0]], right_edges=[a[1]])\n",
    "print(\"U node\")\n",
    "print(u.tensor)\n",
    "print()\n",
    "print(\"V* node\")\n",
    "print(vh.tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:27:21.619735Z",
     "start_time": "2020-06-10T19:27:21.609647Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "DGlRgZq82LP2",
    "outputId": "aa0d0859-acb6-40d2-a625-ac21e38bbc00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contraction of U and V*:\n",
      "[[2.  0.  0. ]\n",
      " [0.  2.5 0. ]\n",
      " [0.  0.  1.5]]\n"
     ]
    }
   ],
   "source": [
    "# Now, we can contract u and vh to get back our original tensor!\n",
    "print(\"Contraction of U and V*:\")\n",
    "print((u @ vh).tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TkBXbOC65qnj"
   },
   "source": [
    "We can also drop the lowest singular values in 2 ways, \n",
    "1. By setting `max_singular_values`. This is the maximum number of the original\n",
    "singular values that we want to keep.\n",
    "2. By setting `max_trun_error`. This is the maximum amount the sum of the removed singular values can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:27:34.213264Z",
     "start_time": "2020-06-10T19:27:34.204440Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "jQZQn4T32YJ3",
    "outputId": "5423113b-3b06-46e5-a890-9ab3da678dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.  0.  0. ]\n",
      " [0.  2.5 0. ]\n",
      " [0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "# We can also drop the lowest singular values in 2 ways, \n",
    "# 1. By setting max_singular_values. This is the maximum number of the original\n",
    "# singular values that we want to keep.\n",
    "a = tn.Node(diagonal_array)\n",
    "u, vh, truncation_error = tn.split_node(\n",
    "    a, left_edges=[a[0]], right_edges=[a[1]], max_singular_values=2)\n",
    "# Notice how the two largest singular values (2.0 and 2.5) remain\n",
    "# but the smallest singular value (1.5) is removed.\n",
    "print((u @ vh).tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYXIXUYY3nf7"
   },
   "source": [
    "We can see the values of the removed singular values by looking at the returned `truncation_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:27:35.313173Z",
     "start_time": "2020-06-10T19:27:35.306821Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PXL9HSmJ3OWe",
    "outputId": "528f4c65-ef26-4454-8fe0-728735f7b41e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5]\n"
     ]
    }
   ],
   "source": [
    "# truncation_error is just a normal tensorflow tensor.\n",
    "print(truncation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ycqQuPYSEnP2"
   },
   "source": [
    "# Section 4: running on GPUs\n",
    "\n",
    "To get this running on a GPU, we recommend using the JAX backend, as it has nearly the exact same API as numpy.\n",
    "\n",
    "To get a GPU, go to Runtime -> Change runtime type -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:28:25.544616Z",
     "start_time": "2020-06-10T19:27:37.432787Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "vQKueu8aEqwM",
    "outputId": "862514f1-d44e-480c-fcc9-161cc379cedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Backend\n",
      "3.62 s ± 151 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "JAX Backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/jax/lib/xla_bridge.py:125: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.28 s ± 278 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def calculate_abc_trace(a, b, c):\n",
    "    an = tn.Node(a)\n",
    "    bn = tn.Node(b)\n",
    "    cn = tn.Node(c)\n",
    "    an[1] ^ bn[0]\n",
    "    bn[1] ^ cn[0]\n",
    "    cn[1] ^ an[0]\n",
    "    return (an @ bn @ cn).tensor\n",
    "\n",
    "a = np.ones((4096, 4096))\n",
    "b = np.ones((4096, 4096))\n",
    "c = np.ones((4096, 4096))\n",
    "\n",
    "tn.set_default_backend(\"numpy\")\n",
    "print(\"Numpy Backend\")\n",
    "%timeit calculate_abc_trace(a, b, c)\n",
    "tn.set_default_backend(\"jax\")\n",
    "# Running with a GPU: 202 ms\n",
    "# Running with a CPU: 2960 ms\n",
    "print(\"JAX Backend\")\n",
    "%timeit np.array(calculate_abc_trace(a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T20:53:38.194031Z",
     "start_time": "2020-06-10T20:51:25.514644Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GaJpprAMWI7S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX Backend\n",
      "14.1 s ± 889 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "tn.set_default_backend(\"pytorch\")\n",
    "\n",
    "print(\"Pytorch Backend\")\n",
    "%timeit np.array(calculate_abc_trace(a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T20:55:40.607241Z",
     "start_time": "2020-06-10T20:55:38.450549Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GaJpprAMWI7S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf Backend\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Tensorflow not installed, please switch to a different backend or install Tensorflow.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m          Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensornetwork/backends/tensorflow/tensorflow_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;31m#pylint: disable=import-outside-toplevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-82653ce47d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf Backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'np.array(calculate_abc_trace(a, b, c))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-2d5fd25d1482>\u001b[0m in \u001b[0;36mcalculate_abc_trace\u001b[0;34m(a, b, c)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_abc_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0man\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0man\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0mbn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensornetwork/network_components.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor, name, axis_names, backend)\u001b[0m\n\u001b[1;32m    548\u001b[0m       \u001b[0mbackend_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mbackend_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     super().__init__(\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensornetwork/backends/backend_factory.py\u001b[0m in \u001b[0;36mget_backend\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_INSTANTIATED_BACKENDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0m_INSTANTIATED_BACKENDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_BACKENDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_INSTANTIATED_BACKENDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensornetwork/backends/tensorflow/tensorflow_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       raise ImportError(\"Tensorflow not installed, please switch to a \"\n\u001b[0m\u001b[1;32m     40\u001b[0m                         \"different backend or install Tensorflow.\")\n\u001b[1;32m     41\u001b[0m     \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Tensorflow not installed, please switch to a different backend or install Tensorflow."
     ]
    }
   ],
   "source": [
    "tn.set_default_backend(\"tensorflow\")\n",
    "\n",
    "print(\"tf Backend\")\n",
    "%timeit np.array(calculate_abc_trace(a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T02:49:08.438873Z",
     "start_time": "2020-06-11T02:48:59.664863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape (2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)\n",
      "5.26 ms ± 593 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "res shape (2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)\n",
      "4.42 ms ± 276 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def cache_eff1(a,b):\n",
    "    an = tn.Node(a)\n",
    "    bn = tn.Node(b)\n",
    "    x = an[0] ^ bn[0]\n",
    "    return tn.contract(x)\n",
    "\n",
    "def cache_eff2(a,b):\n",
    "    an = tn.Node(a)\n",
    "    bn = tn.Node(b)\n",
    "    x = an[-1] ^ bn[-1]\n",
    "    return tn.contract(x)\n",
    "\n",
    "tn.set_default_backend(\"numpy\")\n",
    "\n",
    "a = np.ones([2]*20)\n",
    "b = np.ones([2]*2)\n",
    "print('a shape', a.shape)\n",
    "\n",
    "t = cache_eff1(a,b)\n",
    "%timeit t = cache_eff1(a,b)\n",
    "print('res shape', t.shape)\n",
    "%timeit cache_eff2(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tensor Network Tutorial",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
